# Geopolitical-Risk
# -*- coding: utf-8 -*-
"""script.ipynb

# IMPORTS AND SETTINGS
"""
!pip install linearmodels
import pandas as pd
import statsmodels.api as sm
from statsmodels.formula.api import ols
from linearmodels.panel import PanelOLS, RandomEffects
from statsmodels.api import add_constant
from linearmodels.panel import compare
import numpy as np
import scipy.stats
from linearmodels.panel import FirstDifferenceOLS
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tsa.stattools import adfuller
from statsmodels.stats.diagnostic import het_breuschpagan
import os
import warnings
warnings.filterwarnings('ignore')

# Set project folder
project_folder=os.getcwd()

# DATA READING
filename = os.path.join(project_folder, "Regression data", "panel_regression_data.csv")
data = pd.read_csv(panel_regression_data.csv)
data = data.set_index(['Country', 'Year'])
data = data.dropna(axis=1, how="all")
data.head(20)

# Logarithmic transformations
# Apply log transformation to variables with large values or skewed distributions
data["log_GDP_per_capita"] = np.log(data["GDP/capita"])
data["log_Tech_Advancement_CN"] = np.log(data["Tech Advancement CN"] + 1)  # Adding 1 to avoid log(0)
data["log_Fixed_Asset_Investment_CN_T1"] = np.log(data["Fixed Asset Investment CN (T-1)"] + 1)
data["log_Avg_Wage_Difference"] = np.log(data["Avg Wage Difference"] + 1)

# Lagged variables
# Create lagged versions of independent variables (by one year)
data["lag_GDP_per_capita"] = data.groupby(level=0)["GDP/capita"].shift(1)
data["lag_Tech_Advancement_CN"] = data.groupby(level=0)["Tech Advancement CN"].shift(1)
data["lag_Avg_Wage_Difference"] = data.groupby(level=0)["Avg Wage Difference"].shift(1)

# Interaction terms
# Create interaction terms between independent variables
data["GDP_Tech_Interaction"] = data["GDP/capita"] * data["Tech Advancement CN"]
data["Wage_Environ_Interaction"] = data["Avg Wage Difference"] * data["Environ. St. Difference"]

# Dropping any rows with missing values after transformation
data = data.dropna()

# Dependent, independent, and control variables
data["constant"] = 1
dependent_var = data['Import Share'].to_frame()

# Updated independent variables including lags, logs, and interactions
independent_vars = data[[
    "log_GDP_per_capita", "log_Tech_Advancement_CN", "log_Avg_Wage_Difference",
    "lag_GDP_per_capita", "lag_Tech_Advancement_CN", "lag_Avg_Wage_Difference",
    "GDP_Tech_Interaction", "Wage_Environ_Interaction"
]]

# Multicollinearity Check
vif = pd.DataFrame()
vif["VIF Factor"] = [variance_inflation_factor(independent_vars.values, i) for i in range(independent_vars.shape[1])]
vif["features"] = independent_vars.columns
print("Variance Inflation Factors (VIF):")
print(vif)

# Drop variables with high multicollinearity (VIF > 10 as a rule of thumb)
independent_vars = independent_vars.drop(columns=["GDP_Tech_Interaction"])  # Example drop, adjust as needed
independent_vars.columns

# MODELS
# Fixed Effects Model
fe_model = PanelOLS(dependent_var, independent_vars, entity_effects=True) # Added this code block for fe_results to be defined
fe_results = fe_model.fit()

# Random Effects Model (since Hausman suggests RE is more appropriate)
re_model = RandomEffects(dependent_var, independent_vars)
re_results = re_model.fit()
# -*- coding: utf-8 -*-
"""script-Copy1.ipynb
Automatically generated by Colab.

# IMPORTS AND SETTINGS
"""

import pandas as pd
import statsmodels.api as sm
from statsmodels.formula.api import ols
from linearmodels.panel import PanelOLS, RandomEffects
from statsmodels.api import add_constant
from linearmodels.panel import compare
import numpy as np
import scipy.stats
from linearmodels.panel import FirstDifferenceOLS
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.diagnostic import het_breuschpagan
import os
import warnings
warnings.filterwarnings('ignore')

project_folder = os.getcwd()

"""# DATA READING"""

# Read data
filename2 = os.path.join(project_folder, "Regression data", "panel_regression_absolute.csv")
data2 = pd.read_csv(os.path.join(project_folder, filename2))

# Set index and drop columns with all NaNs
data2 = data2.set_index(['Country', 'Year']).dropna(axis=1, how="all")
data2.head(20)

# Describe the dataset
data2.describe().T

"""# VARIABLE MANIPULATIONS"""

# Logarithmic transformations to handle large values and potential non-linearity
data2["log_GDP_per_capita"] = np.log(data2["GDP/capita"] + 1)
data2["log_Tech_Advancement_CN"] = np.log(data2["Tech Advancement CN"] + 1)

# Lagging variables by one year to account for delayed effects
data2["lag_GDP_per_capita"] = data2.groupby(level=0)["GDP/capita"].shift(1)
data2["lag_Tech_Advancement_CN"] = data2.groupby(level=0)["Tech Advancement CN"].shift(1)

# Drop missing rows after lagging
data2 = data2.dropna()

# Scaling to adjust for large magnitude differences
# Scaling down large variables for better interpretability
data2.loc[:, ["GDP/capita", "Tech Advancement CN", "Fixed Asset Investment CN (T-1)", "Avg Wage Difference"]] = data2.loc[:, ["GDP/capita", "Tech Advancement CN", "Fixed Asset Investment CN (T-1)", "Avg Wage Difference"]].div(1000)
data2["Import"] = data2["Import"].div(1000000)

# Show updated data
data2.describe().T

"""# MODELING"""

# Dependent and independent variables
data2["constant"] = 1
dependent_var = data2['Import'].to_frame()
independent_vars = data2[['log_GDP_per_capita', 'log_Tech_Advancement_CN', 'lag_GDP_per_capita', 'lag_Tech_Advancement_CN']]

# Check for multicollinearity with VIF
vif = pd.DataFrame()
vif["VIF Factor"] = [variance_inflation_factor(independent_vars.values, i) for i in range(independent_vars.shape[1])]
vif["features"] = independent_vars.columns
print("Variance Inflation Factors (VIF):")
print(vif)

"""# FIXED EFFECTS MODEL"""

# Entity Fixed Effects Model (One-way)
fe_model = PanelOLS(dependent_var, independent_vars, entity_effects=True)
fe_results = fe_model.fit()
print("Fixed Effects Model Results:")
print(fe_results)

# Two-way Fixed Effects Model (Entity and Time effects)
two_way_fe_model = PanelOLS(dependent_var, independent_vars, entity_effects=True, time_effects=True, drop_absorbed=True)
two_way_fe_results = two_way_fe_model.fit()
print("Two-Way Fixed Effects Model Results:")
print(two_way_fe_results)

"""# RANDOM EFFECTS MODEL"""

# Random Effects Model
re_model = RandomEffects(dependent_var, independent_vars)
re_results = re_model.fit()
print("\nRandom Effects Model Results:")
print(re_results)

"""# HAUSMAN TEST: FIXED VS RANDOM EFFECTS"""

# Perform Durbin-Wu-Hausman test to compare Fixed and Random Effects models
def durbin_wu_hausman_test(fe_results, re_results):
    u_fe = fe_results.resids
    u_re = re_results.resids
    dw_hausman_stat = np.sum((u_fe - u_re) ** 2) / np.sum(u_fe ** 2)
    df = fe_results.df_model - re_results.df_model
    p_value = 1 - scipy.stats.chi2.cdf(dw_hausman_stat, df)
    return dw_hausman_stat, p_value

dw_hausman_stat, p_value = durbin_wu_hausman_test(fe_results, re_results)
print("Durbin-Wu-Hausman Test Statistic:", dw_hausman_stat)
print("P-value:", p_value)

# If p-value is small (typically < 0.05), Fixed Effects is preferred over Random Effects

"""# BREUSCH-PAGAN TEST FOR HETEROSCEDASTICITY"""

# Breusch-Pagan test for heteroscedasticity
residuals = fe_results.resids
bp_test = het_breuschpagan(residuals, independent_vars)
labels = ['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value']
print(dict(zip(labels, bp_test)))
# -*- coding: utf-8 -*-
"""Improved script based on suggestions"""

"""# IMPORTS AND SETTINGS"""
import pandas as pd
import statsmodels.api as sm
from linearmodels.panel import PanelOLS, RandomEffects
from statsmodels.api import add_constant
from linearmodels.panel import compare
import numpy as np
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.diagnostic import het_breuschpagan
from scipy.stats import chi2
import os
import warnings
warnings.filterwarnings('ignore')

project_folder = os.getcwd()

"""# DATA READING"""

# data from Excel
filename3 = os.path.join(project_folder, "Regression data", "panel_regression_all.csv")
data3 = pd.read_csv(os.path.join(project_folder, filename3))

# 'Country' as entity and 'Year' as time
data3 = data3.set_index(['Country', 'Year'])
data3 = data3.dropna(axis=1, how="all")
data3.head(20)

data3.info()

# Data scaling for selected variables (to improve model fit)
data3.loc[:, ["GDP/capita", "Tech Advancement CN", "Fixed Asset Investment CN (T-1)", "Avg Wage Difference"]] = data3.loc[:, ["GDP/capita", "Tech Advancement CN", "Fixed Asset Investment CN (T-1)", "Avg Wage Difference"]].div(1000)
data3.loc[:, "Import"] = data3.loc[:, "Import"].div(1000000)
data3.describe().T

"""# MODELING SETUP"""

# Set dependent, independent, and control variables
data3["constant"] = 1
dependent_var = data3['Import'].to_frame()
independent_vars = data3.iloc[:, 1:]

# Drop insignificant or redundant variables based on VIF and correlation matrix
independent_vars = independent_vars.drop(columns=["constant", "Fixed Asset Investment CN (T-1)", "Avg Wage Difference"], errors='ignore')

# Calculate Variance Inflation Factor (VIF) to check multicollinearity
vif = pd.DataFrame()
vif["VIF Factor"] = [variance_inflation_factor(independent_vars.values, i) for i in range(independent_vars.shape[1])]
vif["features"] = independent_vars.columns
print("Variance Inflation Factors (VIF):")
print(vif)

"""# MODELS

## Fixed Effects Model (Entity One-Way)
"""
# Check correlation matrix and matrix rank to avoid multicollinearity
corr_matrix = independent_vars.corr()
print(corr_matrix)

def matrix_rank_check(df):
    return np.linalg.matrix_rank(df.values)

print(f"Rank of independent variables matrix: {matrix_rank_check(independent_vars)}")
print(f"Number of columns in independent variables: {independent_vars.shape[1]}")

# Fit Fixed Effects Model (entity effects only)
fe_model = PanelOLS(dependent_var, independent_vars, entity_effects=True)
fe_results = fe_model.fit()

print("Fixed Effects Model Results:")
print(fe_results)

"""## Fixed Effects Model (Two-Way)"""

# Two-way Fixed Effects Model (with time and entity effects)
two_model = PanelOLS(dependent_var, independent_vars, entity_effects=True, time_effects=True, drop_absorbed=True)
two_results = two_model.fit()

print("Two-Way Fixed Effects Model Results:")
print(two_results)

"""## Random Effects Model"""

# Random Effects Model
re_model = RandomEffects(dependent_var, independent_vars)
re_results = re_model.fit()

print("\nRandom Effects Model Results:")
print(re_results)

# Compare Fixed and Random Effects Models using Hausman Test
comparison = compare({"Fixed": fe_results, "Random": re_results})
print(comparison)

"""## Durbin-Wu-Hausman Test for Endogeneity"""

def durbin_wu_hausman_test(ols_fixed, ols_random):
    """Perform the Durbin-Wu-Hausman test for endogeneity."""
    u_fe = ols_fixed.resids  # Residuals from FE model
    u_re = ols_random.resids  # Residuals from RE model
    dw_hausman_stat = np.sum((u_fe - u_re)**2) / np.sum(u_fe**2)
    df = fe_results.df_model - re_results.df_model
    p_value = 1 - chi2.cdf(dw_hausman_stat, df)
    return dw_hausman_stat, p_value

# Perform the Durbin-Wu-Hausman test
dw_hausman_stat, p_value = durbin_wu_hausman_test(fe_results, re_results)
print("Durbin-Wu-Hausman Test Statistic:", dw_hausman_stat)
print("P-value:", p_value)

"""## Wald Test"""

# Wald test: checks if regressors are collectively insignificant
wald_result = fe_results.wald_test(formula="Fit=0, `GDP/capita`=0, `Energy Consumption`=0, `Annual Solar Capacity Addition`=0, `Tech Advancement CN`=0, `TechAdvancement `=0, `Trade Policies EU`=0, `Environ. St. Difference`=0")
print(wald_result)

"""## Breusch-Pagan Test for Heteroskedasticity"""

# Perform Breusch-Pagan test
residuals = fe_results.resids
independent_vars_bp_test = independent_vars.copy()
independent_vars_bp_test["constant"] = 1

bp_test = het_breuschpagan(resid=residuals, exog_het=independent_vars_bp_test, robust=True)
labels = ['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value']
print(dict(zip(labels, bp_test)))
